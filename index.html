<!DOCTYPE html>
<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script
    async
    src="https://www.googletagmanager.com/gtag/js?id=UA-178132094-1"
  ></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() {
      dataLayer.push(arguments);
    }
    gtag("js", new Date());

    gtag("config", "UA-178132094-1");
  </script>

  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>AdvBench: Adversarial robustness benchmark</title>
  <link
    rel="stylesheet"
    href="https://cdn.rawgit.com/jpswalsh/academicons/master/css/academicons.min.css"
  />
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script
    id="MathJax-script"
    async
    src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"
  ></script>
  <script
    src="https://kit.fontawesome.com/b939870cfb.js"
    crossorigin="anonymous"
  ></script>
  <link
    rel="stylesheet"
    href="https://cdnjs.cloudflare.com/ajax/libs/foundation/6.4.3/css/foundation.min.css"
  />
  <link
    rel="stylesheet"
    href="https://cdn.datatables.net/1.10.21/css/dataTables.foundation.min.css"
  />

  <script
    type="text/javascript"
    src="https://code.jquery.com/jquery-3.5.1.js"
  ></script>
  <script
    type="text/javascript"
    src="https://cdn.datatables.net/1.10.21/js/jquery.dataTables.min.js
    "
  ></script>
  <script
    type="text/javascript"
    src="https://cdn.datatables.net/1.10.21/js/dataTables.foundation.min.js"
  ></script>
  <script>
    $(document).ready(function () {
      $("#leaderboard1").DataTable({
        lengthMenu: [15, 25, 50, 75, 100],
      });
    });
    $(document).ready(function () {
      $("#leaderboard2").DataTable({
        lengthMenu: [15, 25, 50, 75, 100],
      });
    });
  </script>

  <link rel="stylesheet" href="./css/main.css" />
</head>

<body>
  <div id="navbar" class="nav">
    <div class="fixed-width-navbar">
      <ul class="left">
        <li><a href="#">AdvBench</a></li>
      </ul>
      <ul class="right">
        <li><a href="#leaderboard">Leaderboard</a></li>
        <li><a href="#contribute">Contribute</a></li>
        <li><a href="https://github.com/AdvBench/advbench">Model Zoo ðŸš€</a></li>
      </ul>
    </div>
  </div>

  <!-- <hr class="toprule" /> -->

  <header>
    <div class="logo"><img src="./images/logo.png" alt="logo" /></div>
    <div class="title">AdvBench</div>
    <div class="description">
      A standardized benchmark for adversarial robustness
    </div>
  </header>
  <!-- <hr class="toprule" /> -->

  <!-- <hr class="title-rule" /> -->
  <div class="content">
    <section id="introduction">
      <div class="overview">
        <p class="doublealign">
          The goal of <strong>AdvBench</strong> is to systematically track the
          <em>real</em> progress in adversarial robustness. There are already
          <a
            href="https://nicholas.carlini.com/writing/2019/all-adversarial-example-papers.html"
            >more than 2&#39;000 papers</a
          >
          on this topic, but it is still unclear which approaches
          <em>really</em> work and which only lead to
          <a href="https://arxiv.org/abs/1802.00420">overestimated robustness</a
          >. We start from benchmarking the Linf- and L2-robustness since these
          are the most studied settings in the literature. We plan to extend the
          benchmark to other threat models in the future: first to other
          Lp-norms and then to more general perturbation sets.
          <strong>AdvBench</strong> provides two key modules:
        </p>
        <div class="flexbox-container features">
          <div class="element">
            <div class="icon">
              <img
                src="https://img.icons8.com/wired/100/000000/leaderboard.png"
              />
            </div>
            <p>
              Up-to-date leaderboard based <br />
              on 30+ recent papers
            </p>
          </div>
          <div class="element">
            <div class="icon">
              <img
                src="https://img.icons8.com/ios-glyphs/80/000000/user-credentials.png"
              />
            </div>
            <p>
              Unified access to 20+ state-of-the-art <br />robust models via
              Model Zoo
            </p>
          </div>
        </div>
      </div>
      <div class="details">
        <div class="box usage">
          <p>Model Zoo</p>
          <div class="divider"><hr /></div>
          Check out our
          <a href="https://github.com/AdvBench/advbench#notebooks"
            >Colab tutorials</a
          >
          for a quick start.
          <div class="codeblock">
            <div class="vspace10"></div>
            <!--            <pre><code></code>-->
            <!--!pip install git+https://github.com/AdvBench/advbench-->

            <!--from advbench.utils import load_model-->
            <!--model = load_model(model_name='Carmon2019Unlabeled')-->

            <!--from advbench.data import load_cifar10-->
            <!--x_test, y_test = load_cifar10(n_examples=100)-->

            <!--!pip install -q git+https://github.com/fra31/auto-attack-->
            <!--from autoattack import AutoAttack-->
            <!--adversary = AutoAttack(model, norm='Linf', eps=8/255)-->
            <!--x_adv = adversary.run_standard_evaluation(x_test, y_test)-->
            <!-- HTML generated using hilite.me -->
            <div
              style="
                background: #ffffff;
                overflow: auto;
                width: auto;
                border: solid gray;
                border-width: 0em 0em 0em 0em;
                padding: 0.2em 0.6em;
              "
            >
              <pre
                style="margin: 0; line-height: 125%"
              ><span style="color: #888888">!pip install git+https://github.com/AdvBench/advbench</span>

<span style="color: #008800; font-weight: bold">from</span> <span style="color: #0e84b5; font-weight: bold">advbench.utils</span> <span style="color: #008800; font-weight: bold">import</span> load_model
model <span style="color: #333333">=</span> load_model(model_name<span style="color: #333333">=</span><span style="background-color: #fff0f0">&#39;Carmon2019Unlabeled&#39;</span>)

<span style="color: #008800; font-weight: bold">from</span> <span style="color: #0e84b5; font-weight: bold">advbench.data</span> <span style="color: #008800; font-weight: bold">import</span> load_cifar10
x_test, y_test <span style="color: #333333">=</span> load_cifar10(n_examples<span style="color: #333333">=</span><span style="color: #0000DD; font-weight: bold">100</span>)

<span style="color: #888888">!pip install git+https://github.com/fra31/auto-attack</span>
<span style="color: #008800; font-weight: bold">from</span> <span style="color: #0e84b5; font-weight: bold">autoattack</span> <span style="color: #008800; font-weight: bold">import</span> AutoAttack
adversary <span style="color: #333333">=</span> AutoAttack(model, norm<span style="color: #333333">=</span><span style="background-color: #fff0f0">&#39;Linf&#39;</span>, eps<span style="color: #333333">=</span><span style="color: #0000DD; font-weight: bold">8</span><span style="color: #333333">/</span><span style="color: #0000DD; font-weight: bold">255</span>)
x_adv <span style="color: #333333">=</span> adversary<span style="color: #333333">.</span>run_standard_evaluation(x_test, y_test)
</pre>
            </div>
          </div>
        </div>
        <div class="box images">
          <p>Analysis</p>
          <div class="divider"><hr /></div>
          Check out the <a href="#">complete report</a> with a detailed
          analysis.
          <div class="scroller analysis-images">
            <img
              src="./images/aa_robustness_vs_venues.png"
              alt="robustness_vs_venues"
            />
            <!--            <img-->
            <!--              src="./images/aa_robustness_vs_clean.png"-->
            <!--              alt="robustness_vs_clean"-->
            <!--            />-->
          </div>
        </div>
      </div>
      <div class="vspace30"></div>
    </section>

    <section id="leaderboard">
      <div class="heading">
        <p>
          Leaderboard:
          <span class="heading-math">CIFAR-10, \( \ell_\infty = 8/255 \)</span>
        </p>
      </div>
      <table id="leaderboard1" class="datatable" style="width: 100%">
        <thead>
          <tr>
            <th class="rank">Rank</th>
            <th class="method">Method</th>
            <th class="ca">
              Clean <br />
              accuracy
            </th>
            <th class="aa">
              Adversarial <br />
              accuracy
            </th>
            <th class="extra-data">Extra <br />data</th>
            <th class="arch">Architecture</th>
            <th class="venue">Venue</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td class="ranktd">1</td>
            <td class="methoddt">
              <a href="https://arxiv.org/abs/1905.13736"
                >Unlabeled Data Improves Adversarial Robustness</a
              >
            </td>
            <td class="catd">89.69</td>
            <td class="aatd">59.53</td>
            <td class="datatd">&#9745;</td>
            <td class="archtd">WideResNet-28-10</td>
            <td class="venuetd">NeurIPS 2019</td>
          </tr>
          <tr>
            <td class="ranktd">2</td>
            <td class="methoddt">
              <a href="https://arxiv.org/abs/2002.10509"
                >HYDRA: Pruning Adversarially Robust Neural Networks</a
              >
            </td>
            <td class="catd">88.98</td>
            <td class="aatd">57.14</td>
            <td class="datatd">&#9745;</td>
            <td class="archtd">WideResNet-28-10</td>
            <td class="venuetd">N/A</td>
          </tr>
          <tr>
            <td class="ranktd">3</td>
            <td class="methoddt">
              <a href="https://openreview.net/forum?id=rklOg6EFwS"
                >Improving Adversarial Robustness Requires Revisiting
                Misclassified Examples</a
              >
            </td>
            <td class="catd">87.50</td>
            <td class="aatd">56.29</td>
            <td class="datatd">&#9745;</td>
            <td class="archtd">WideResNet-28-10</td>
            <td class="venuetd">ICLR 2020</td>
          </tr>
          <tr>
            <td class="ranktd">4</td>
            <td class="methoddt">
              <a href="https://arxiv.org/abs/1905.13725"
                >Are Labels Required for Improving Adversarial Robustness?</a
              >
            </td>
            <td class="catd">86.46</td>
            <td class="aatd">56.03</td>
            <td class="datatd">&#9745;</td>
            <td class="archtd">WideResNet-28-10</td>
            <td class="venuetd">NeurIPS 2019</td>
          </tr>
          <tr>
            <td class="ranktd">5</td>
            <td class="methoddt">
              <a href="https://arxiv.org/abs/1901.09960"
                >Using Pre-Training Can Improve Model Robustness and
                Uncertainty</a
              >
            </td>
            <td class="catd">87.11</td>
            <td class="aatd">54.92</td>
            <td class="datatd">&#9745;</td>
            <td class="archtd">WideResNet-28-10</td>
            <td class="venuetd">ICML 2019</td>
          </tr>
          <tr>
            <td class="ranktd">6</td>
            <td class="methoddt">
              <a href="https://arxiv.org/abs/2002.08619"
                >Boosting Adversarial Training with Hypersphere Embedding</a
              >
            </td>
            <td class="catd">85.14</td>
            <td class="aatd">53.74</td>
            <td class="datatd">&#9746;</td>
            <td class="archtd">WideResNet-34-20</td>
            <td class="venuetd">N/A</td>
          </tr>
          <tr>
            <td class="ranktd">7</td>
            <td class="methoddt">
              <a href="https://arxiv.org/abs/2002.11569"
                >Overfitting in adversarially robust deep learning</a
              >
            </td>
            <td class="catd">85.34</td>
            <td class="aatd">53.42</td>
            <td class="datatd">&#9746;</td>
            <td class="archtd">WideResNet-34-20</td>
            <td class="venuetd">ICML 2020</td>
          </tr>
          <tr>
            <td class="ranktd">8</td>
            <td class="methoddt">
              <a href="https://arxiv.org/abs/2002.10319"
                >Self-Adaptive Training: beyond Empirical Risk Minimization</a
              >
              <br /><span class="td-footer"
                >Uses \(\ell_{\infty} \) = 0.031 â‰ˆ 7.9/255 instead of 8/255.
              </span>
            </td>
            <td class="catd">83.48</td>
            <td class="aatd">53.34</td>
            <td class="datatd">&#9746;</td>
            <td class="archtd">WideResNet-34-10</td>
            <td class="venuetd">N/A</td>
          </tr>
          <tr>
            <td class="ranktd">9</td>
            <td class="methoddt">
              <a href="https://arxiv.org/abs/1901.08573"
                >Theoretically Principled Trade-off between Robustness and
                Accuracy</a
              >
              <br /><span class="td-footer"
                >Uses \(\ell_{\infty}\) = 0.031 â‰ˆ 7.9/255 instead of 8/255.
              </span>
            </td>
            <td class="catd">84.92</td>
            <td class="aatd">53.08</td>
            <td class="datatd">&#9746;</td>
            <td class="archtd">WideResNet-34-10</td>
            <td class="venuetd">ICML 2019</td>
          </tr>
          <tr>
            <td class="ranktd">10</td>
            <td class="methoddt">
              <a href="https://arxiv.org/abs/1907.02610v2"
                >Adversarial Robustness through Local Linearization</a
              >
            </td>
            <td class="catd">86.28</td>
            <td class="aatd">52.84</td>
            <td class="datatd">&#9746;</td>
            <td class="archtd">WideResNet-40-8</td>
            <td class="venuetd">NeurIPS 2019</td>
          </tr>
          <tr>
            <td class="ranktd">11</td>
            <td class="methoddt">
              <a href="https://arxiv.org/abs/2003.12862"
                >Adversarial Robustness: From Self-Supervised Pre-Training to
                Fine-Tuning</a
              >
              <br /><span class="td-footer">Uses ensembles of 3 models</span>
            </td>
            <td class="catd">86.04</td>
            <td class="aatd">51.56</td>
            <td class="datatd">&#9746;</td>
            <td class="archtd">ResNet-50</td>
            <td class="venuetd">CVPR 2020</td>
          </tr>
          <tr>
            <td class="ranktd">12</td>
            <td class="methoddt">
              <a href="https://github.com/MadryLab/robustness"
                >Robustness library</a
              >
            </td>
            <td class="catd">87.03</td>
            <td class="aatd">49.25</td>
            <td class="datatd">&#9746;</td>
            <td class="archtd">ResNet-50</td>
            <td class="venuetd">N/A</td>
          </tr>
          <tr>
            <td class="ranktd">13</td>
            <td class="methoddt">
              <a href="https://arxiv.org/abs/1905.05186"
                >Harnessing the Vulnerability of Latent Layers in Adversarially
                Trained Models</a
              >
            </td>
            <td class="catd">87.80</td>
            <td class="aatd">49.12</td>
            <td class="datatd">&#9746;</td>
            <td class="archtd">WideResNet-34-10</td>
            <td class="venuetd">IJCAI 2019</td>
          </tr>
          <tr>
            <td class="ranktd">14</td>
            <td class="methoddt">
              <a
                href="http://papers.nips.cc/paper/8339-metric-learning-for-adversarial-robustness"
                >Metric Learning for Adversarial Robustness</a
              >
            </td>
            <td class="catd">86.21</td>
            <td class="aatd">47.41</td>
            <td class="datatd">&#9746;</td>
            <td class="archtd">WideResNet-34-10</td>
            <td class="venuetd">NeurIPS 2019</td>
          </tr>
          <tr>
            <td class="ranktd">15</td>
            <td class="methoddt">
              <a href="https://arxiv.org/abs/1905.00877"
                >You Only Propagate Once: Accelerating Adversarial Training via
                Maximal Principle</a
              >
            </td>
            <td class="catd">87.20</td>
            <td class="aatd">44.83</td>
            <td class="datatd">&#9746;</td>
            <td class="archtd">WideResNet-34-10</td>
            <td class="venuetd">NeurIPS 2019</td>
          </tr>
          <tr>
            <td class="ranktd">16</td>
            <td class="methoddt">
              <a href="https://arxiv.org/abs/1706.06083"
                >Towards Deep Learning Models Resistant to Adversarial
                Attacks</a
              >
            </td>
            <td class="catd">87.14</td>
            <td class="aatd">44.04</td>
            <td class="datatd">&#9746;</td>
            <td class="archtd">WideResNet-34-10</td>
            <td class="venuetd">ICLR 2018</td>
          </tr>
          <tr>
            <td class="ranktd">17</td>
            <td class="methoddt">
              <a href="https://arxiv.org/abs/1905.10626"
                >Rethinking Softmax Cross-Entropy Loss for Adversarial
                Robustness</a
              >
            </td>
            <td class="catd">80.89</td>
            <td class="aatd">43.48</td>
            <td class="datatd">&#9746;</td>
            <td class="archtd">ResNet-32</td>
            <td class="venuetd">ICLR 2020</td>
          </tr>
          <tr>
            <td class="ranktd">18</td>
            <td class="methoddt">
              <a href="https://arxiv.org/abs/2001.03994"
                >Fast is better than free: Revisiting adversarial training</a
              >
            </td>
            <td class="catd">83.34</td>
            <td class="aatd">43.21</td>
            <td class="datatd">&#9746;</td>
            <td class="archtd">ResNet-18</td>
            <td class="venuetd">ICLR 2020</td>
          </tr>
          <tr>
            <td class="ranktd">19</td>
            <td class="methoddt">
              <a href="https://arxiv.org/abs/1904.12843"
                >Adversarial Training for Free!</a
              >
            </td>
            <td class="catd">86.11</td>
            <td class="aatd">41.47</td>
            <td class="datatd">&#9746;</td>
            <td class="archtd">WideResNet-34-10</td>
            <td class="venuetd">NeurIPS 2019</td>
          </tr>
          <tr>
            <td class="ranktd">20</td>
            <td class="methoddt">
              <a href="https://openreview.net/forum?id=HkeryxBtPB"
                >MMA Training: Direct Input Space Margin Maximization through
                Adversarial Training</a
              >
            </td>
            <td class="catd">84.36</td>
            <td class="aatd">41.44</td>
            <td class="datatd">&#9746;</td>
            <td class="archtd">WideResNet-28-4</td>
            <td class="venuetd">ICLR 2020</td>
          </tr>
          <tr>
            <td class="ranktd">21</td>
            <td class="methoddt">
              <a href="https://arxiv.org/abs/1905.11911"
                >Controlling Neural Level Sets</a
              >
              <br />
              <span class="td-footer"
                >Uses \(\ell_{\infty}\) = 0.031 â‰ˆ 7.9/255 instead of 8/255.
              </span>
            </td>
            <td class="catd">81.30</td>
            <td class="aatd">40.22</td>
            <td class="datatd">&#9746;</td>
            <td class="archtd">ResNet-18</td>
            <td class="venuetd">NeurIPS 2019</td>
          </tr>
          <tr>
            <td class="ranktd">22</td>
            <td class="methoddt">
              <a
                href="http://openaccess.thecvf.com/content_CVPR_2019/html/Moosavi-Dezfooli_Robustness_via_Curvature_Regularization_and_Vice_Versa_CVPR_2019_paper"
                >Robustness via Curvature Regularization, and Vice Versa</a
              >
            </td>
            <td class="catd">83.11</td>
            <td class="aatd">38.50</td>
            <td class="datatd">&#9746;</td>
            <td class="archtd">ResNet-18</td>
            <td class="venuetd">CVPR 2019</td>
          </tr>
          <tr>
            <td class="ranktd">23</td>
            <td class="methoddt">
              <a
                href="http://papers.nips.cc/paper/8459-defense-against-adversarial-attacks-using-feature-scattering-based-adversarial-training"
                >Defense Against Adversarial Attacks Using Feature
                Scattering-based Adversarial Training</a
              >
            </td>
            <td class="catd">89.98</td>
            <td class="aatd">36.64</td>
            <td class="datatd">&#9746;</td>
            <td class="archtd">WideResNet-28-10</td>
            <td class="venuetd">NeurIPS 2019</td>
          </tr>
          <tr>
            <td class="ranktd">24</td>
            <td class="methoddt">
              <a
                href="https://openreview.net/forum?id=Syejj0NYvr&noteId=Syejj0NYvr"
                >Adversarial Interpolation Training: A Simple Approach for
                Improving Model Robustness</a
              >
            </td>
            <td class="catd">90.25</td>
            <td class="aatd">36.45</td>
            <td class="datatd">&#9746;</td>
            <td class="archtd">WideResNet-28-10</td>
            <td class="venuetd">N/A</td>
          </tr>
          <tr>
            <td class="ranktd">25</td>
            <td class="methoddt">
              <a
                href="http://openaccess.thecvf.com/content_ICCV_2019/html/Jang_Adversarial_Defense_via_Learning_to_Generate_Diverse_Attacks_ICCV_2019_paper.html"
                >Adversarial Defense via Learning to Generate Diverse Attacks</a
              >
            </td>
            <td class="catd">78.91</td>
            <td class="aatd">34.95</td>
            <td class="datatd">&#9746;</td>
            <td class="archtd">ResNet-20</td>
            <td class="venuetd">ICCV 2019</td>
          </tr>
          <tr>
            <td class="ranktd">26</td>
            <td class="methoddt">
              <a href="https://openreview.net/forum?id=rJlf_RVKwr"
                >Sensible adversarial learning</a
              >
            </td>
            <td class="catd">91.51</td>
            <td class="aatd">34.22</td>
            <td class="datatd">&#9746;</td>
            <td class="archtd">WideResNet-34-10</td>
            <td class="venuetd">N/A</td>
          </tr>
          <tr>
            <td class="ranktd">27</td>
            <td class="methoddt">
              <a
                href="http://openaccess.thecvf.com/content_ICCV_2019/html/Wang_Bilateral_Adversarial_Training_Towards_Fast_Training_of_More_Robust_Models_ICCV_2019_paper.html"
                >Bilateral Adversarial Training: Towards Fast Training of More
                Robust Models Against Adversarial Attacks</a
              >
            </td>
            <td class="catd">92.80</td>
            <td class="aatd">29.35</td>
            <td class="datatd">&#9746;</td>
            <td class="archtd">WideResNet-28-10</td>
            <td class="venuetd">ICCV 2019</td>
          </tr>
          <tr>
            <td class="ranktd">28</td>
            <td class="methoddt">
              <a href="https://arxiv.org/abs/1905.10510"
                >Enhancing Adversarial Defense by k-Winners-Take-All</a
              >
              <br /><span class="td-footer">
                Uses \(\ell_{\infty}\) = 0.031 â‰ˆ 7.9/255 instead of 8/255.
              </span>
            </td>
            <td class="catd">79.28</td>
            <td class="aatd">18.50</td>
            <td class="datatd">&#9746;</td>
            <td class="archtd">DenseNet-121</td>
            <td class="venuetd">ICLR 2020</td>
          </tr>
          <tr>
            <td class="ranktd">29</td>
            <td class="methoddt">
              <a href="https://arxiv.org/abs/2003.04286"
                >Manifold Regularization for Adversarial Robustness</a
              >
            </td>
            <td class="catd">90.84</td>
            <td class="aatd">1.35</td>
            <td class="datatd">&#9746;</td>
            <td class="archtd">ResNet-18</td>
            <td class="venuetd">N/A</td>
          </tr>
          <tr>
            <td class="ranktd">30</td>
            <td class="methoddt">
              <a href="https://arxiv.org/abs/1904.00887"
                >Adversarial Defense by Restricting the Hidden Space of Deep
                Neural Networks</a
              >
            </td>
            <td class="catd">89.16</td>
            <td class="aatd">0.28</td>
            <td class="datatd">&#9746;</td>
            <td class="archtd">ResNet-110</td>
            <td class="venuetd">ICCV 2019</td>
          </tr>
          <tr>
            <td class="ranktd">31</td>
            <td class="methoddt">
              <a href="https://arxiv.org/abs/1912.10185"
                >Jacobian Adversarially Regularized Networks for Robustness</a
              >
            </td>
            <td class="catd">93.79</td>
            <td class="aatd">0.26</td>
            <td class="datatd">&#9746;</td>
            <td class="archtd">WideResNet-34-10</td>
            <td class="venuetd">ICLR 2020</td>
          </tr>
          <tr>
            <td class="ranktd">32</td>
            <td class="methoddt">
              <a href="https://arxiv.org/abs/2006.07682"
                >ClusTR: Clustering Training for Robustness
              </a>
            </td>
            <td class="catd">91.03</td>
            <td class="aatd">0.00</td>
            <td class="datatd">&#9746;</td>
            <td class="archtd">WideResNet-28-10</td>
            <td class="venuetd">N/A</td>
          </tr>
          <tr>
            <td class="ranktd">33</td>
            <td class="methoddt"><a href="">Naturally trained model</a></td>
            <td class="catd">94.78</td>
            <td class="aatd">0.0</td>
            <td class="datatd">&#9746;</td>
            <td class="archtd">WideResNet-28-10</td>
            <td class="venuetd">N/A</td>
          </tr>
        </tbody>
      </table>
    </section>

    <section>
      <div class="heading">
        <p>
          Leaderboard:
          <span class="heading-math">CIFAR-10, \( \ell_2 = 0.5 \)</span>
        </p>
      </div>
      <table id="leaderboard2" class="datatable" style="width: 100%">
        <thead>
          <tr>
            <th class="rank">Rank</th>
            <th class="method">Method</th>
            <th class="ca">
              Clean <br />
              accuracy
            </th>
            <th class="aa">
              Adversarial <br />
              accuracy
            </th>
            <th class="extra-data">Extra <br />data</th>
            <th class="arch">Architecture</th>
            <th class="venue">Venue</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td class="ranktd">1</td>
            <td class="methoddt">
              <a href="https://arxiv.org/abs/2003.09461" target="_blank"
                >Adversarial Robustness on In- and Out-Distribution Improves
                Explainability</a
              >
            </td>
            <td class="catd">91.08</td>
            <td class="aatd">72.91</td>
            <td class="datatd">&#9745;</td>
            <td class="archtd">ResNet-50</td>
            <td class="venuetd">ECCV 2020</td>
          </tr>
          <tr>
            <td class="ranktd">2</td>
            <td class="methoddt">
              <a href="https://github.com/MadryLab/robustness" target="_blank"
                >Robustness library</a
              >
            </td>
            <td class="catd">90.83</td>
            <td class="aatd">69.24</td>
            <td class="datatd">&#9746;</td>
            <td class="archtd">ResNet-50</td>
            <td class="venuetd">N/A</td>
          </tr>
          <tr>
            <td class="ranktd">3</td>
            <td class="methoddt">
              <a href="https://arxiv.org/abs/2002.11569" target="_blank"
                >Overfitting in adversarially robust deep learning</a
              >
            </td>
            <td class="catd">88.67</td>
            <td class="aatd">67.68</td>
            <td class="datatd">&#9746;</td>
            <td class="archtd">ResNet-18</td>
            <td class="venuetd">ICML 2020</td>
          </tr>
          <tr>
            <td class="ranktd">4</td>
            <td class="methoddt">
              <a href="https://arxiv.org/abs/1811.09600" target="_blank"
                >Decoupling Direction and Norm for Efficient Gradient-Based L2
                Adversarial Attacks and Defenses</a
              >
            </td>
            <td class="catd">89.05</td>
            <td class="aatd">66.44</td>
            <td class="datatd">&#9746;</td>
            <td class="archtd">WideResNet-28-10</td>
            <td class="venuetd">CVPR 2019</td>
          </tr>
          <tr>
            <td class="ranktd">5</td>
            <td class="methoddt">
              <a
                href="https://openreview.net/forum?id=HkeryxBtPB"
                target="_blank"
                >MMA Training: Direct Input Space Margin Maximization through
                Adversarial Training</a
              >
            </td>
            <td class="catd">88.02</td>
            <td class="aatd">66.09</td>
            <td class="datatd">&#9746;</td>
            <td class="archtd">WideResNet-28-4</td>
            <td class="venuetd">ICLR 2020</td>
          </tr>
          <tr>
            <td class="ranktd">6</td>
            <td class="methoddt">
              <a href="" target="_blank">Naturally trained model</a>
            </td>
            <td class="catd">94.78</td>
            <td class="aatd">0.0</td>
            <td class="datatd">&#9746;</td>
            <td class="archtd">WideResNet-28-10</td>
            <td class="venuetd">N/A</td>
          </tr>
        </tbody>
      </table>
    </section>

    <section id="contribute">
      <!--
      <div class="heading"><p>Contributions</p></div>
      <hr />
      <p class="doublealign">
      Some details on welcoming contributions. Quisque id ullamcorper sem. In
      hac habitasse platea dictumst. Suspendisse a semper libero. Nullam a enim
      non nisi ultricies cursus. Quisque eu tincidunt dolor. Fusce non risus eu
      purus tempor auctor. Fusce et placerat turpis. Proin aliquet lorem mi, at
      tempus sapien ornare id. Mauris accumsan, nulla vel posuere sollicitudin,
      nisi massa tristique mauris, eget ullamcorper risus tellus a nibh.
      Curabitur tempus dignissim magna in sagittis.
      </p>


      <div class="vspace30"></div>
      -->
      <div class="details">
        <div class="box2">
          <p>Contribute to AdvBench!</p>
          <div class="divider"><hr /></div>
          We welcome any contribution in terms of both new robust models and
          evaluations. Please check <a href=""> here</a> for more details.
          <br />
          <br />
          Feel free to contact us at
          <a href="mailto:adversarial.benchmark@gmail.com"
            >adversarial.benchmark@gmail.com</a
          >
        </div>
        <div class="box2">
          <p>Maintainers</p>
          <div class="divider"><hr /></div>
          <ul>
            <li>
              <a href="https://twitter.com/fra__31" target="_blank"
                >Francesco Croce
              </a>
              <a href="https://twitter.com/fra__31"
                ><i class="fas fa-globe"></i
              ></a>
              <a href="https://github.com/fra31"
                ><i class="fab fa-github"></i
              ></a>
              <a href="https://scholar.google.com/citations?user=laq9cq0AAAAJ"
                ><i class="ai ai-google-scholar"></i
              ></a>
            </li>
            <li>
              <a
                href="https://people.epfl.ch/maksym.andriushchenko"
                target="_blank"
                >Maksym Andriushchenko</a
              >
              <a href="https://people.epfl.ch/maksym.andriushchenko"
                ><i class="fas fa-globe"></i
              ></a>
              <a href="https://github.com/max-andr"
                ><i class="fab fa-github"></i
              ></a>
              <a href="https://scholar.google.com/citations?user=ZNtuJYoAAAAJ"
                ><i class="ai ai-google-scholar"></i
              ></a>
            </li>
            <li>
              <a href="https://vsehwag.github.io/" target="_blank"
                >Vikash Sehwag</a
              >
              <a href="https://vsehwag.github.io/"
                ><i class="fas fa-globe"></i
              ></a>
              <a href="https://github.com/VSehwag"
                ><i class="fab fa-github"></i
              ></a>
              <a href="https://scholar.google.com/citations?user=JAkeEG8AAAAJ"
                ><i class="ai ai-google-scholar"></i
              ></a>
            </li>
          </ul>
        </div>
      </div>
    </section>
  </div>

  <hr class="bottomrule" />

  <footer>
    <small
      >&copy; 2020, AdvBench;
      <a href="https://icons8.com/icon/100413/access"
        >Icons from Icons8</a
      ></small
    >
  </footer>

  <script>
    // When the user scrolls the page, execute myFunction
    window.onscroll = function () {
      myFunction();
    };
    // Get the navbar
    var navbar = document.getElementById("navbar");
    // Get the offset position of the navbar
    var sticky = navbar.offsetTop;
    // Add the sticky class to the navbar when you reach its scroll position. Remove "sticky" when you leave the scroll position
    function myFunction() {
      if (window.pageYOffset >= sticky) {
        navbar.classList.add("sticky");
      } else {
        navbar.classList.remove("sticky");
      }
    }
  </script>
</body>
