<!DOCTYPE html>
<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script
    async
    src="https://www.googletagmanager.com/gtag/js?id=UA-178132094-1"
  ></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() {
      dataLayer.push(arguments);
    }
    gtag("js", new Date());

    gtag("config", "UA-178132094-1");
  </script>

  <meta charset="UTF-8" />
  <!--  <meta name="viewport" content="width=device-width, initial-scale=1" />-->
  <meta name="viewport" content="width=1024" />
  <title>AdvBench: Adversarial robustness benchmark</title>
  <link
    rel="stylesheet"
    href="https://cdn.rawgit.com/jpswalsh/academicons/master/css/academicons.min.css"
  />
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script
    id="MathJax-script"
    async
    src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"
  ></script>
  <script
    src="https://kit.fontawesome.com/b939870cfb.js"
    crossorigin="anonymous"
  ></script>
  <link
    rel="stylesheet"
    href="https://cdnjs.cloudflare.com/ajax/libs/foundation/6.4.3/css/foundation.min.css"
  />
  <link
    rel="stylesheet"
    href="https://cdn.datatables.net/1.10.21/css/dataTables.foundation.min.css"
  />
  <script>
    $(document).ready(function () {
      $("#leaderboard1").DataTable({
        lengthMenu: [15, 25, 50, 75, 100],
      });
    });
    $(document).ready(function () {
      $("#leaderboard2").DataTable({
        lengthMenu: [15, 25, 50, 75, 100],
      });
    });
  </script>

  <link rel="stylesheet" href="./css/main.css" />
</head>

<style>
  p {
    font-size: 1.2em;
    line-height: 1.4em;
  }
  .question {
    font-weight: bold;
  }
  .answer {
    margin-left: 30px;
  }
</style>
<body>
  <div id="navbar" class="nav">
    <div class="fixed-width-navbar">
      <ul class="left">
        <li><a href="./index.html#">AdvBench</a></li>
      </ul>
      <ul class="right">
        <li><a href="./index.html#leaderboard">Leaderboard</a></li>
        <li><a href="#">FAQ</a></li>
        <li><a href="./index.html#contribute">Contribute</a></li>
        <li><a href="https://github.com/AdvBench/advbench">Model Zoo ðŸš€</a></li>
      </ul>
    </div>
  </div>

  <!-- <hr class="toprule" /> -->

  <header></header>
  <!-- <hr class="toprule" /> -->

  <!-- <hr class="title-rule" /> -->
  <div class="content">
    <p>
      The goal of AdvBench is to systematically track the real progress in
      adversarial robustness and provide an easy access to state-of-the-robust
      models.
    </p>

    <p class="qa-box">
      <span class="question"
        >&#10148; Wait, how is it different from
        <a href="https://www.robust-ml.org/">robust-ml.org</a>? ðŸ¤”
      </span>
      <br />
      <span class="answer"
        ><a href="https://www.robust-ml.org/">robust-ml.org</a> focuses on
        <em>adaptive</em> evaluations, but we provide a
        <strong>standardized benchmark</strong>. Adaptive evaluations are great
        (e.g., see
        <a href="https://arxiv.org/abs/2002.08347">Tramer et al., 2020</a>) but
        very time consuming and not standardized.</span
      >
    </p>

    <p class="qa-box">
      <span class="question"
        >&#10148; How is it related to libraries like
        <a href="https://github.com/bethgelab/foolbox">foolbox</a> /
        <a href="https://github.com/tensorflow/cleverhans">cleverhans</a> /
        <a href="https://github.com/BorealisAI/advertorch">advertorch</a>? ðŸ¤”
      </span>
      <br />
      <span class="answer"
        >These libraries provide implementations of different <em>attacks</em>.
        Besides the standardized benchmark,
        <strong>AdvBench</strong> additionally provides a repository of the most
        robust models. So you can start using the robust models in one line of
        code (see the tutorial
        <a href="https://github.com/AdvBench/advbench">here</a>).</span
      >
    </p>

    <p class="qa-box">
      <span class="question"
        >&#10148; I've heard that Lp-robustness is boring. Why would you even
        evaluate Lp-robustness in 2020? ðŸ¤”
      </span>
      <br />
      <span class="answer"
        >There are numerous interesting applications of Lp-robustness that span
        transfer learning (<a href="https://arxiv.org/abs/2007.08489"
          >Salman et al. (2020)</a
        >, <a href="https://arxiv.org/abs/2007.05869">Utrera et al. (2020)</a>),
        interpretability (<a href="https://arxiv.org/abs/1805.12152"
          >Tsipras et al. (2018)</a
        >, <a href="https://arxiv.org/abs/1910.08640">Kaur et al. (2019)</a>,
        <a href="https://arxiv.org/abs/1906.00945">Engstrom et al. (2019)</a>),
        security (<a href="https://arxiv.org/abs/1811.03194"
          >TramÃ¨r et al. (2018)</a
        >,
        <a href="https://arxiv.org/abs/1906.07153">Saadatpanah et al. (2019)</a
        >), generalization (<a href="https://arxiv.org/abs/1911.09665"
          >Xie et al. (2019)</a
        >, <a href="https://arxiv.org/abs/1909.11764">Zhu et al. (2019)</a>,
        <a href="https://arxiv.org/abs/2004.10934">Bochkovskiy et al. (2020)</a
        >), robustness to unseen perturbations (<a
          href="https://arxiv.org/abs/1911.09665"
          >Xie et al. (2019)</a
        >, <a href="https://arxiv.org/abs/1905.01034">Kang et al. (2019)</a>),
        stabilization of GAN training (<a
          href="https://arxiv.org/abs/2008.03364"
          >Zhong et al. (2020)</a
        >).</span
      >
    </p>

    <p class="qa-box">
      <span class="question"
        >&#10148; Is this benchmark only focused on Lp-robustness? ðŸ¤”
      </span>
      <br />
      <span class="answer"
        >Not at all! Lp-robustness is the most well-studied area, so we focus on
        it first. However, in the future, we plan to extend the benchmark to
        other perturbations sets beyond Lp-balls.</span
      >
    </p>

    <p class="qa-box">
      <span class="question"
        >&#10148; What if I have a better attack than the one used in this
        benchmark? ðŸ¤”
      </span>
      <br />
      <span class="answer"
        >We will be happy to add a better attack or any adaptive evaluation that
        would complement our default standardized attacks.</span
      >
    </p>

    <p class="qa-box">
      <span class="question">&#10148; What about verified robustness? ðŸ¤” </span>
      <br />
      <span class="answer"
        >We specifically focus on defenses which improves empirical robustness,
        given the limited progress on it despite hundreds of proposed defenses.
        For methods targeting verfied robustness, we encourage readers to check
        out following resource - [<a
          href="https://github.com/AI-secure/VeriGauge"
          >1</a
        >,
        <a href="https://github.com/Hadisalman/robust-verify-benchmark">2</a>]
      </span>
    </p>
  </div>

  <hr class="bottomrule" />

  <footer>
    <small>&copy; 2020, AdvBench</small>
  </footer>

  <script>
    // When the user scrolls the page, execute myFunction
    window.onscroll = function () {
      myFunction();
    };
    // Get the navbar
    var navbar = document.getElementById("navbar");
    // Get the offset position of the navbar
    var sticky = navbar.offsetTop;
    // Add the sticky class to the navbar when you reach its scroll position. Remove "sticky" when you leave the scroll position
    function myFunction() {
      if (window.pageYOffset >= sticky) {
        navbar.classList.add("sticky");
      } else {
        navbar.classList.remove("sticky");
      }
    }
  </script>
</body>
